---
title: "Machine Learning 1"
author: "Ralph Goguanco"
date: "2/14/2022"
output: html_document
---

# First up kmeans()

Demo of using kmeans() function in base R. First make up some data with a known structure.


```{r}
tmp <- c(rnorm(30, -3), rnorm(30, 3) )
x <- cbind(x=tmp, y=rev(tmp))
plot(x)
```
Now we have some made up data in 'x' let's see how kmeans works with this data

```{r}
k <- kmeans(x, centers = 2, nstart = 20)
k
```

> Q. How many points are in each cluster

```{r}
k$size

```
> Q. How do we get to the cluster membership/assignment.

```{r}
k$cluster
```

> Q. What about cluster centers

```{r}
k$centers
```

Now we got to the main results let's use them to plot our data with the kmeans result

```{r}
plot(x, col=k$cluster)
points(k$centers, col="blue", pch=15)
```

## Now for hclust()

We will cluster the same data 'x' with the 'hclust()' In this case 'hclust()' requires a distance matrrix as input.

```{r}
hc <- hclust( dist(x))
hc
```

Let's plot our hclust results

```{r}
plot(hc)
```

To get our cluster membership vector we need to "cut" the tree with 'cutree()' 

```{r}
grps <- cutree(hc, h=8)
grps
```

Now plot our data with the hclust() results

```{r}
plot(x, col=grps)
```

# Principal Component Analysis (PCA)

## PCA of UK food data

Read data from website and try a few visualizations.

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
x 
```

```{r}
cols <- rainbow(nrow(x))
barplot( as.matrix(x), col=cols )
cols
```

```{r}
barplot( as.matrix(x), col=cols, beside=TRUE)
```


```{r}
pairs(x, col=cols)
```